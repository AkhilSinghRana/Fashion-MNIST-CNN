{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN approach for fashion-MNIST\n",
    "\n",
    "This notebook shows different approaches to solve FashionMNIST problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required data\n",
    "You can find the dataset and further informations at Zalando:\n",
    "- https://github.com/zalandoresearch/fashion-mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call the script from train.py or main.py\n",
      "Namespace(batch_size=250, exp_name='Experiment_1', img_h=28, img_w=28, load_dir='saved_models', mode='train', model_arch='custom', num_aug=2, num_channels=1, num_classes=10, num_epochs=10, optimizer='Adam', save_dir='saved_models')\n"
     ]
    }
   ],
   "source": [
    "#Import options from options.py needed for dataloading and generating models\n",
    "import sys, os\n",
    "\n",
    "%run ../code/options.py\n",
    "%run ../code/util/dataLoader.py\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "args = parseArguments()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 60000\n",
      "Test Samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Generate Data Loader\n",
    "dataloader = DataLoader(args)\n",
    "(X_train, y_train), (X_test, y_test) = dataloader.generateData()\n",
    "\n",
    "#Class mappign usefull for plotting\n",
    "fashion_classes     = {0: 'T-shirt/top', \n",
    "                       1: 'Trouser', \n",
    "                       2: 'Pullover', \n",
    "                       3: 'Dress', \n",
    "                       4: 'Coat',\n",
    "                       5: 'Sandal', \n",
    "                       6: 'Shirt', \n",
    "                       7: 'Sneaker', \n",
    "                       8: 'Bag', \n",
    "                       9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Sandal\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "idx = np.random.randint(len(X_train))\n",
    "plt.imshow(np.squeeze(X_train[idx]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Target:\", fashion_classes[y_train[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation (optional)\n",
    "This method will increase the raw data by data augmentation of images. I just added rotation, horizontal flip and fill mode. Feel free to change these settings. These settings can be found in dataLoader.py\n",
    "Processing of raw images:\n",
    "- Scaling pixels between 0.0-1.0\n",
    "- Add augmentated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting images...\n",
      "*Preprocessing completed: 60000 samples\n",
      "\n",
      "Augmenting images...\n",
      "*Preprocessing completed: 10000 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Perform data Augmentation\n",
    "X_train_shaped, y_train_shaped = dataloader.preprocess_data(\n",
    "                                        X_train, y_train, \n",
    "                                        use_augmentation=False, \n",
    "                                        nb_of_augmentation=args.num_aug\n",
    "                                        )\n",
    "X_test_shaped, y_test_shaped   = dataloader.preprocess_data(X_test,  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate model now, all models ared defined isnide code/util/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 848,522\n",
      "Trainable params: 848,330\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../code/util/model.py\n",
    "\n",
    "args.model_arch=\"v1\"\n",
    "model_obj = GenerateModel(args)\n",
    "cnn_model = model_obj.cnn_model() #Default Architecture is Custom finetuned\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training\n",
    "Run training for number of iterations by random data for train/validation. The best model of each iteration will be saved as hdf5 checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47250/48000 [============================>.] - ETA: 0s - loss: 0.7232 - accuracy: 0.7442\n",
      "Epoch 00001: val_loss improved from inf to 1.68117, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 7s 145us/sample - loss: 0.7190 - accuracy: 0.7458 - val_loss: 1.6812 - val_accuracy: 0.4688\n",
      "Epoch 2/10\n",
      "47500/48000 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.8408\n",
      "Epoch 00002: val_loss improved from 1.68117 to 0.99916, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.4350 - accuracy: 0.8410 - val_loss: 0.9992 - val_accuracy: 0.6366\n",
      "Epoch 3/10\n",
      "47750/48000 [============================>.] - ETA: 0s - loss: 0.3763 - accuracy: 0.8614\n",
      "Epoch 00003: val_loss improved from 0.99916 to 0.35818, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.3767 - accuracy: 0.8614 - val_loss: 0.3582 - val_accuracy: 0.8640\n",
      "Epoch 4/10\n",
      "47250/48000 [============================>.] - ETA: 0s - loss: 0.3431 - accuracy: 0.8730\n",
      "Epoch 00004: val_loss improved from 0.35818 to 0.31932, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.3433 - accuracy: 0.8728 - val_loss: 0.3193 - val_accuracy: 0.8781\n",
      "Epoch 5/10\n",
      "47250/48000 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.8830\n",
      "Epoch 00005: val_loss improved from 0.31932 to 0.27242, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.3186 - accuracy: 0.8827 - val_loss: 0.2724 - val_accuracy: 0.8979\n",
      "Epoch 6/10\n",
      "47750/48000 [============================>.] - ETA: 0s - loss: 0.3029 - accuracy: 0.8881\n",
      "Epoch 00006: val_loss did not improve from 0.27242\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.3032 - accuracy: 0.8880 - val_loss: 0.2999 - val_accuracy: 0.8854\n",
      "Epoch 7/10\n",
      "47750/48000 [============================>.] - ETA: 0s - loss: 0.2850 - accuracy: 0.8958\n",
      "Epoch 00007: val_loss improved from 0.27242 to 0.24709, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.2852 - accuracy: 0.8957 - val_loss: 0.2471 - val_accuracy: 0.9097\n",
      "Epoch 8/10\n",
      "47750/48000 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.8998\n",
      "Epoch 00008: val_loss did not improve from 0.24709\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.2705 - accuracy: 0.8997 - val_loss: 0.2504 - val_accuracy: 0.9058\n",
      "Epoch 9/10\n",
      "47750/48000 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9036\n",
      "Epoch 00009: val_loss improved from 0.24709 to 0.22912, saving model to fashion_mnist-0.hdf5\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.2602 - accuracy: 0.9036 - val_loss: 0.2291 - val_accuracy: 0.9150\n",
      "Epoch 10/10\n",
      "47750/48000 [============================>.] - ETA: 0s - loss: 0.2539 - accuracy: 0.9062\n",
      "Epoch 00010: val_loss did not improve from 0.22912\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.2541 - accuracy: 0.9061 - val_loss: 0.2406 - val_accuracy: 0.9134\n",
      "Total time taken =  52.12390327453613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "histories = []\n",
    "\n",
    "i=0\n",
    "# Saving the best checkpoint for each iteration\n",
    "filepath = \"fashion_mnist-%i.hdf5\" % i\n",
    "\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_shaped, y_train_shaped,\n",
    "                                                      test_size=0.2, random_state=42)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "history = cnn_model.fit(\n",
    "    X_train_, y_train_,\n",
    "    batch_size=args.batch_size,\n",
    "    epochs=args.num_epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val_, y_val_),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    ]\n",
    ")\n",
    "end = time.time()\n",
    "print(\"Total time taken = \", end-start)\n",
    "histories.append(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainingscores for loss and accuracy for all checkpoints\n",
    "Please remind that checkpoints will be saved by minimum loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \t0.26018157 loss / 0.90362501 acc\n",
      "Validation: \t0.22911881 loss / 0.91500002 acc\n"
     ]
    }
   ],
   "source": [
    "def get_avg(histories, his_key):\n",
    "    tmp = []\n",
    "    for history in histories:\n",
    "        tmp.append(history[his_key][np.argmin(history['val_loss'])])\n",
    "    return np.mean(tmp)\n",
    "    \n",
    "print('Training: \\t%0.8f loss / %0.8f acc'   % (get_avg(histories,'loss'), get_avg(histories,'accuracy')))\n",
    "print('Validation: \\t%0.8f loss / %0.8f acc' % (get_avg(histories,'val_loss'), get_avg(histories,'val_accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss / accuracy of all models on testset\n",
    "Determine loss and accuracy of all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final test with model 0: 0.2419 loss / 0.9092 acc\n",
      "\n",
      "Average loss / accuracy on testset: 0.2419 loss / 0.90920 acc\n",
      "Standard deviation: (+-0.0000) loss / (+-0.0000) acc\n"
     ]
    }
   ],
   "source": [
    "test_loss = []\n",
    "test_accs = []\n",
    "\n",
    "for i in range(0,1):\n",
    "    cnn_ = tf.keras.models.load_model(\"fashion_mnist-%i.hdf5\" % i)\n",
    "    \n",
    "    score = cnn_.evaluate(X_test_shaped, y_test_shaped, verbose=0)\n",
    "    test_loss.append(score[0])\n",
    "    test_accs.append(score[1])\n",
    "    \n",
    "    print('Running final test with model %i: %0.4f loss / %0.4f acc' % (i,score[0],score[1]))\n",
    "    \n",
    "print('\\nAverage loss / accuracy on testset: %0.4f loss / %0.5f acc' % (np.mean(test_loss),np.mean(test_accs)))\n",
    "print('Standard deviation: (+-%0.4f) loss / (+-%0.4f) acc' % (np.std(test_loss),np.std(test_accs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FashionMNIST",
   "language": "python",
   "name": "fashionmnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
